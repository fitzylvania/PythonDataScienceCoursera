{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyton for Data Science Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Series Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The series is one of the core data structures in pandas. You think of it a cross between a list and a dictionary. The items are all stored in an order and there's labels with which you can retrieve them. An easy way to visualize this is two columns of data. The first is the special index, a lot like the dictionary keys. While the second is your actual data. It's important to note that the data column has a label of its own and can be retrieved using the .name attribute. This is different than with dictionaries and is useful when it comes to merging multiple columns of data. And we'll talk about that later on in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, you can create a series by passing in a list of values. When you do this, Pandas automatically assigns an index starting with zero and sets the name of the series to None. Let's see an example of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll start off by importing the pandas library as pd, then let's take a look at the series object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be anything, that's array-like, like a list. So let's give that a try. We'll just make a list of the three of my favorite animals, a tiger, a bear and a moose. We'll see here that the pandas has automatically identified the type of the data being held in the list, in this case we passed in a list of strings and panda set the type to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2    Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = ['Tiger','Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to use strings. If we passed in a list of whole numbers, for instance, we could see that panda sets the type to n 64. Underneath panda stores series values in a typed array using the Numpy library. This offers significant speed-up when processing data versus traditional python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1,2,3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some other typing details that exist for performance that are important to know. The most important is how Numpy and thus pandas handle missing data. In Python, we have the none type to indicate a lack of data. But what do we do if we want to have a typed list like we do in the series object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underneath, pandas does some type conversion. If we create a list of strings and we have one element, a None type, pandas inserts it as a None and uses the type object for the underlying array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2     None\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = ['Tiger','Bear',None]\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we create a list of numbers, integers or floats, and put in the None type, pandas automatically converts this to a special floating point value designated as NAN, which stands for not a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1,2,None]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who might not have done scientific computing in Python before, this is a pretty important point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.nan == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAN is not none and when we try the equality test, it's false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that you actually can't do an equality test of NAN to itself. When you do, the answer is always false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to use special functions to test for the presence of not a number, such as the Numpy library is NAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll come back to this later in the assignment, but keep in mind when you see NAN, it's meaning is similar to none, but it's a numeric value and it's treated differently for efficiency reasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk more about how pandas' series can be created. While my list of animals might be a common way to create some play data, often you have label data that you want to manipulate. A series can be created from dictionary data.\n",
    "> Ok, so note that the variable is loaded with a dictionary, then the pandas series is created from the variable - Fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery':'Bhutan',\n",
    "          'Golf':'Scotland',\n",
    "          'Sumo':'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do this, the index is automatically assigned to the keys of the dictionary that you provided and not just incrementing integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Archery', 'Golf', 'Sumo', 'Taekwondo'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using some data from Wikipedia on official national sports. When we create the series, we see that, since it was string data, panda set the data type of the series to object. We set the list of the countries as the value of the series and that the index values can be set to the keys from our dictionary.<br>\n",
    "So what happens if your list of values in the index object are not aligned with the keys in your dictionary for creating the series? <br>\n",
    "Well, pandas overrides the automatic creation to favor only and all of the indices values that you provided. So it will ignore it from your dictionary, all keys, which are not in your index, and pandas will add non type or NAN values for any index value you provide, which is not in your dictionary key list. In this example, we pass in a dictionary of four items but only two are preserved in the series object because of the index list. We see that hockey has been added but since it's also in the index list, it has no value associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Golf      Scotland\n",
       "Sumo         Japan\n",
       "Hockey         NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery':'Bhutan',\n",
    "          'Golf':'Scotland',\n",
    "         'Sumo':'Japan',\n",
    "         'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports, index=['Golf','Sumo','Hockey'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the series has been created, we can get the index object using the index attribute. You could also separate your index creation from the data by passing in the index as a list explicitly to the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Golf', 'Sumo', 'Hockey'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not sure why he had this piece of code in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India      Tiger\n",
       "America     Bear\n",
       "Canada     Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Tiger','Bear','Moose'], index=['India', 'America','Canada'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's how we create a series. In the next class, we'll dig deeper and look at how we get data out of the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A panda.Series can be queried, either by the index position or the index label. As we saw, if you don't give an index to the series, the position and the label are effectively the same values.<br>  \n",
    "Here's an example using national sporting event data from Wikipedia<br>\n",
    "Let's say we want to have a list of all of the sports in our index and a list of countries as values. You might keep these in a dictionary and create a series as we discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query by numeric location, starting at zero, use the <b>`iloc`</b> attribute.<br><br>\n",
    "If you wanted to see the fourth country on this, we would use the <b>`iloc`</b> attribute with the parameter 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query by the index label, you can use the <b>`loc`</b> attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to see which country has golf as its national sport, we would use the <b>`loc`</b> attribute with parameter golf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['Golf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that <b>`iloc`</b> and <b>`loc`</b> are not methods, they are attributes. <br><br>\n",
    "So you don't use <b>`()`</b> parentheses to query them, but <b>`[]`</b> square brackets instead, which we'll call the <b>indexing operator</b>. Though in Python, this calls <b>`get`</b> and <b>`set`</b> an item methods depending on the context of its use.<br><br>\n",
    "This might seem a bit confusing if you're used to languages where encapsulation of attributes, variables, and properties is common, such as in Java. <b>`Pandas`</b> tries to make our code a bit more readable and provides a sort of smart syntax using the <b>indexing operator</b> directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want it to query via the <b>`iloc`</b> attribute. If you pass in an object, it will query as if you wanted to use the label based <b>`loc`</b>attribute.<br><br>\n",
    "So what happens if your index is a list of integers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {99: 'Bhutan',\n",
    "          100: 'Scotland',\n",
    "          101: 'Japan',\n",
    "          102: 'South Korea'}\n",
    "s = pd.Series(sports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit complicated, and Pandas can't determine automatically whether you're intending to query by index position or index label. So you need to be careful when using the <b>indexing operator</b> on the series itself. And the safer option is to be more explicit and use the <b>`iloc`</b> or <b>`loc`</b> attributes directly.<br><br>\n",
    "Here's an example using some new sports data, where countries are indexed by integer. If we try and call s sub zero, we get a key error, because there's no item in the sports list with an index of zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-00fa51989f14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#This won't call s.iloc[0] as one might expect, it generates an error instead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4730\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4731\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4732\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "s[0] #This won't call s.iloc[0] as one might expect, it generates an error instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we have to call <b>`iloc`</b> explicitly if we want the first item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now we know how to get data out of the series. Let's talk about working with the data.<br><br>\n",
    "A common task is to want to consider all of the values inside of a series and want to do some sort of operation. This could be trying to find a certain number, summarizing data or transforming the data in some way.<br><br>\n",
    "A typical programmatic approach to this would be to iterate over all the items in the series, and invoke the operation one is interested in. For instance, we could create a data frame of floating point values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([100.00, 120.00, 101.00, 3.00])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think of these as prices for different products. We could write a little routine which iterates over all of the items in the series and adds them together to get a total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for item in s:\n",
    "    total+=item\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but it's slow. Modern computers can do many tasks simultaneously, especially, but not only, tasks involving mathematics.<br><br>\n",
    "Pandas and the underlying <b>`NumPy`</b> libraries support a method of computation called <b>vectorization</b>.<br><br>\n",
    "Vectorization works with most of the functions in the <b>`NumPy`</b> library, including the <b>`sum`</b> function.<br><br>\n",
    "Here's how we would really write the code using the <b>`NumPy`</b> <b>`sum`</b> method. First we need to import the <b>`numpy`</b> module, and then we just call <b>`np.sum`</b> and pass in an <b>iterable item</b>. In this case, our <b>`pandas`</b> <b>`series`</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "total = np.sum(s)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both of these methods create the same value, but is one actually faster? The Jupyter Notebook has a <b>magic function</b> which can help.<br> First, let's create a big series of random numbers. You'll see this used a lot when demonstrating techniques with <b>`Pandas`</b>. Note that I've just used the <b>`head`</b> method, which reduces the amount of data printed out by the series to the first five elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates a big series of random numbers\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually verify that length of the series is correct using the <b>`len`</b> function. <b>Magic functions</b> begin with a <b>`%`</b> percentage sign. If we type this sign and then hit the Tab key, we can see a list of the available magic functions. You could write your own magic functions too, but that's a little bit outside of the scope of this course. We're actually going to use what's called a <b>cellular magic function</b>. These start with two <b>`%%`</b> percentage signs and modify a <b>raptor code</b> in the current Jupyter cell. The function we're going to use is called <b>`timeit`</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc(max(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". And as you may have guessed from the name, this function will run our code a few times to determine, on average, how long it takes.<br><br>\n",
    "Let's run timeit with our original iterative code. You can give timeit the number of loops that you would like to run. By default, we'll use 1,000 loops. I'll ask timeit here to use 100 runs because we're recording this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = 0\n",
    "for item in s:\n",
    "    summary+=item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Timeit ran this code and it doesn't seem like it takes very long at all. Now let's try with <b>vectorization</b>.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = np.sum(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! This is a pretty shocking difference in the speed and demonstrates why data scientists need to be aware of parallel computing features and start thinking in <b>functional programming</b> terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. A quick aside here. Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily. But if you find yourself iterating through a series, you should question whether you're doing things in the best possible way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we would do this using the series <b>`set_value`</b> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, value in s.iteritems():\n",
    "    s.set_value(label, value+2)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and time the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label] = value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "s+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing. Not only is it significantly faster, but it's more concise and maybe even easier to read too. The typical mathematical operations you would expect are <b>vectorized</b>, and the <b>`NumPy`</b> documentation outlines what it takes to create <b>vectorized functions</b> of your own. <br><br>\n",
    "    One last note on using the indexing operators to access series data. The <b>`.loc`</b> attribute lets you not only modify data in place, but also add new data as well. If the value you pass in as the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. While it's important to be aware of the typing going on underneath, <b>`Pandas`</b> will automatically change the underlying <b>`NumPy`</b> types as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using a series of a few numbers. We could add some new value, maybe an animal, as you know, I like bears. Just by calling the .loc indexing operator. We see that mixed types for data values or index labels are no problem for <b>`Pandas`</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3])\n",
    "s.loc['Animal'] = 'Bears'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now I've shown only examples of a series where the index values were unique. I want to end this lecture by showing an example where index values are not unique, and this makes data frames different, conceptually, that a relational database might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the issue of countries and their national sports, it turns out that many countries seem to like this game cricket. We go back to our original series on sports. It's possible to create a new series object with multiple entries for cricket, and then use append to bring these together. There are a couple of important considerations when using append. First, Pandas is going to take your series and try to infer the best data types to use. In this example, everything is a string, so there's no problems here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sports = pd.Series({'Archery': 'Bhutan',\n",
    "                             'Golf': 'Scotland',\n",
    "                             'Sumo': 'Japan',\n",
    "                             'Taekwondo': 'South Korea'})\n",
    "cricket_loving_countries = pd.Series(['Australia',\n",
    "                                      'Barbados',\n",
    "                                      'Pakistan',\n",
    "                                      'England'], \n",
    "                                   index=['Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the append method doesn't actually change the underlying series. It instead returns a new series which is made up of the two appended together. We can see this by going back and printing the original series of values and seeing that they haven't changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = original_sports.append(cricket_loving_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually a significant issue for new Pandas users who are used to objects being changed in place. So watch out for it, not just with append but with other Pandas functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_loving_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that when we query the appended series for those who have cricket as their national sport, we don't get a single value, but a series itself. This is actually very common, and if you have a relational database background, this is very similar to every table query resulting in a return set which itself is a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries.loc['Cricket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we focused on one of the primary data types of the <b>`Pandas`</b> library, the <b>series</b>. There are many more methods associated with this <b>series object</b> that we haven't talked about. But with these basics down, we'll move on to talking about the Panda's two-dimensional data structure, the <b>data frame</b>. The <b>data frame</b> is very similar to the <b>series object</b>, but includes multiple columns of data, and is the structure that you'll spend the majority of your time working with when cleaning and aggregating data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Frame Data Structure\n",
    "The <b>`DataFrame`</b> data structure is the heart of the <b>`Pandas`</b> library. It's a primary object that you'll be working with in data analysis and cleaning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>`DataFrame`</b> is conceptually a two-dimensional <b>series object</b>, where there's an index and multiple columns of content, with each column having a label. In fact, the distinction between a column and a row is really only a conceptual distinction. And you can think of the <b>`DataFrame`</b> itself as simply a two-axes labeled array.<br><br>\n",
    "You can create a <b>`DataFrame`</b> in many different ways, some of which you might expect. For instance, you can use a group of <b>series</b>, where each series represents a row of data. Or you could use a group of <b>dictionaries</b>, where each <b>dictionary</b> represents a row of data.<br><br>\n",
    "Let's take a look at an example. <br>\n",
    "I'm going to create three purchase order records as <b>series objects</b> for a sort of fictional store. Each series has a name of a customer, the string which describes the item being purchased, and the cost of the items. I like dogs, so I'll purchase a bunch of dog food. Kevin Cullens Thompson, the instructor for the third course in the series, he seems more like a cat man to me, so I'll have him purchase some kitty litter. And I think Vinod, who teaches the fourth course in this series, is more of a bird man, so I'll add some bird seed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "purchase_1 = pd.Series({'Name': 'Chris',\n",
    "                        'Item Purchased': 'Dog Food',\n",
    "                        'Cost': 22.50})\n",
    "purchase_2 = pd.Series({'Name': 'Kevyn',\n",
    "                        'Item Purchased': 'Kitty Litter',\n",
    "                        'Cost': 2.50})\n",
    "purchase_3 = pd.Series({'Name': 'Vinod',\n",
    "                        'Item Purchased': 'Bird Seed',\n",
    "                        'Cost': 5.00})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll feed this into the DataFrame as the first argument and set index values indicating which store where each purchase was done. You'll see that when we print out a DataFrame, the Jupiter notebook's trying to pretty it up a bit, and print it out as a table, which is nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([purchase_1, purchase_2, purchase_3], index=['Store 1', 'Store 1', 'Store 2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the series, we can extract data using the <b>`iloc`</b> and <b>`loc`</b> attributes. Because the DataFrame is two-dimensional, passing a single value to the <b>`loc`</b> <b>indexing operator</b> will return series if there's only one row to return.<br><br>\n",
    "In this example, if we wanted to select data associated with Store 2, we would just query the <b>`loc`</b> attribute with one parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that the name of the series is returned as the row index value, while the column name is included in the output as well.<br><br>\n",
    "We can check the data type of the return using the python <b>`type`</b> function. It's important to remember that the indices and column names along either axes, horizontal or vertical, could be non-unique. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['Store 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in this example, we see two purchase records for Store 1 as different rows. If we use a single value with the DataFrame <b>`loc`</b> attribute, multiple rows of the <b>DataFrame</b> will return, not as a new <b>series</b>, but as a new <b>DataFrame</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if we query for Store 1 records, we see that Chris and Kevin both shop at the same pets supply store. One of the powers of the Panda's <b>`DataFrame`</b> is that you can quickly select data based on multiple axes.<br><br>\n",
    "For instance, if you wanted to just list the costs for Store 1, you would supply two parameters to <b>`.loc`</b>, one being the row index and the other being the column name. If we're only interested in Store 1 costs, we could write this as <b>`df.loc('Store 1', 'Cost')`</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1','Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just wanted to do column selection and just get a list of all of the costs? Well, there's a couple of options. First, you can get a transpose of the DataFrame, using the capital T attribute, which swaps all of the columns and rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially turns your column names into indices. And we can then use the <b>`.loc`</b> method. This works, but it's pretty ugly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.loc['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since <b>`iloc`</b> and <b>`loc`</b> are used for row selection, the Panda's developers reserved <b>indexing operator</b> directly on the <b>`DataFrame`</b> for column selection. In a Panda's <b>`DataFrame`</b>, columns always have a name. So this selection is always label based, not as confusing as it was when using the <b>`[]`</b> square bracket operator on the <b>series objects</b>. For those familiar with relational databases, this operator is analogous to column projection.<br><br>\n",
    "Finally, since the result of using the indexing operators, the DataFrame or series, you can chain operations together. For instance, we could have rewritten the query for all Store 1 costs as <b>`df.loc['Store 1', 'Cost']`</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1']['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another method. As we saw, <b>`.loc`</b> does row selection, and it can take two parameters, the row index and the list of column names. <b>`.loc`</b> also supports <b>slicing</b>. If we wanted to select all rows, we can use a column to indicate a full slice from beginning to end. And then add the column name as the second parameter as a string. In fact, if we wanted to include multiply columns, we could do so in a <b>list</b>. And Pandas will bring back only the columns we have asked for.<br><br>\n",
    "Here's an example, where we ask for all of the name and cost values for all stores using the <b>`.loc`</b> operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Name','Cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's selecting and projecting data from a DataFrame based on row and column labels. The key concepts to remember are that the rows and columns are really just for our benefit. Underneath this is just a two axes labeled array, and transposing the columns is easy.<br><br>\n",
    "Also, consider the issue of chaining carefully, and try to avoid it, it can cause unpredictable results. Where your intent was to obtain a view of the data, but instead Pandas returns to you a copy. In the Panda's world, friends don't let friends chain calls. So if you see it, point it out, and share a less ambiguous solution.<br><br>\n",
    "Now, before we leave the discussion of accessing data in DataFrames, let's talk about dropping data.<br><br>\n",
    "It's easy to delete data in series and DataFrames, and we can use the <b>`drop`</b> function to do so. This function takes a single parameter, which is the index or roll label, to drop. This is another tricky place for new users to pad this. The <b>`drop`</b> function doesn't change the <b>`DataFrame`</b> by default. And instead, returns to you a copy of the <b>`DataFrame`</b> with the given rows removed. We can see that our original <b>`DataFrame`</b> is still intact. Let's make a copy with the <b>`copy`</b> method and do a drop on it instead. This is a very typical pattern in Pandas, where in place changes to a DataFrame are only done if need be, usually on changes involving indices. So it's important to be aware of.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Store 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`Drop`</b> has two interesting optional parameters. The first is called <i>in place</i>, and if it's set to <b>true</b>, the <b>`DataFrame`</b> will be updated in place, instead of a copy being returned. The second parameter is the <i>axes</i>, which should be dropped. By default, this value is 0, indicating the row axes. But you could change it to 1 if you want to drop a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "copy_df = copy_df.drop('Store 1')\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df.drop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second way to drop a column, however. And that's directly through the use of the <b>indexing operator</b>, using the <b>`del`</b> keyword.<br><br>\n",
    "This way of dropping data, however, takes immediate effect on the <b>`DataFrame`</b> and does not return a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del copy_df['Name']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, adding a new column to the <b>`DataFrame`</b> is as easy as assigning it to some value. For instance, if we wanted to add a new location as a column with default value of none, we could do so by using the <b>`=`</b> <b>assignment operator</b> after the square brackets. This broadcasts the default value to the new column immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame Indexing and Loading\n",
    "The common work flow is to read your data into a <b>`DataFrame`</b> then reduce this <b>`DataFrame`</b> to the particular columns or rows that you're interested in working with. As you've seen, the Panda's toolkit tries to give you views on a <b>`DataFrame`</b>. This is much faster than copying data and much more memory efficient too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = df['Cost']\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it does mean that if you're manipulating the data you have to be aware that any changes to the <b>`DataFrame`</b> you're working on may have an impact on the base <b>`DataFrame`</b> you used originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs+=2\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using our same purchasing <b>`DataFrame`</b> from earlier. We can create a <b>series</b> based on just the cost category using the square brackets. Then we can increase the cost in this series using <b>broadcasting</b>. Now if we look at our original <b>`DataFrame`</b>, we see those costs have risen as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an important consideration to watch out for. If you want to explicitly use a copy, then you should consider calling the <b>`copy`</b> method on the <b>`DataFrame`</b> for it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we'll be largely using smaller, moderate-sized datasets. As I mentioned, a common workflow is to read the dataset in, usually from some external file. We saw previously how you can do this using Python, and lists, and dictionaries. You can imagine how you might use those dictionaries to create a Pandas DataFrame.<br><br>\n",
    "Thankfully, Pandas has built-in support for delimited files such as CSV files as well as a variety of other data formats including relational databases, Excel, and HTML tables.<br><br>\n",
    "I've saved a CSV file called olympics.csv, which has data from Wikipedia that contains a summary list of the medal various countries have won at the Olympics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at this file using the shell command cat. Which we can invoke directly using the exclamation point.<br>\n",
    "<b>`!cat 'olympics.csv'`</b><br>\n",
    "What happens here is that when the Jupyter notebook sees a line beginning with an exclamation mark, it sends the rest of the line to the operating system shell for evaluation. So cat works on Linux and Macs, as well as in the Coursera platform, but might not work on Windows. You don't need to worry too much about this. I just wanted to show how a Jupyter notebook can integrate with the operating system to provide you with even more tools to look at your data.\n",
    "> NOTE: I could never get this to work on a windows 10 machine.  Don't think cat is a windows operating system command<br>\n",
    "\n",
    "We see from the cat output that there seems to be a numeric list of columns followed by a bunch of column identifiers. The column identifiers have some odd looking characters in them. This is the unicode numero sign, which means number of.<br>\n",
    "Then we have rows of data, all columns separated.<br>\n",
    "We can read this into a DataFrame by calling the read_csv function of the module. When we look at the DataFrame we see that the first cell has an NaN in it since it's an empty value, and the rows have been automatically indexed for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = 'C:/Users/dfitzgerald/Documents/MyCourses/IntrotoDataScienceinPython/coursedownloads/olympics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>№ Summer</td>\n",
       "      <td>01 !</td>\n",
       "      <td>02 !</td>\n",
       "      <td>03 !</td>\n",
       "      <td>Total</td>\n",
       "      <td>№ Winter</td>\n",
       "      <td>01 !</td>\n",
       "      <td>02 !</td>\n",
       "      <td>03 !</td>\n",
       "      <td>Total</td>\n",
       "      <td>№ Games</td>\n",
       "      <td>01 !</td>\n",
       "      <td>02 !</td>\n",
       "      <td>03 !</td>\n",
       "      <td>Combined total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1     2     3     4      5         6     7     8  \\\n",
       "0                NaN  № Summer  01 !  02 !  03 !  Total  № Winter  01 !  02 !   \n",
       "1  Afghanistan (AFG)        13     0     0     2      2         0     0     0   \n",
       "2      Algeria (ALG)        12     5     2     8     15         3     0     0   \n",
       "3    Argentina (ARG)        23    18    24    28     70        18     0     0   \n",
       "4      Armenia (ARM)         5     1     2     9     12         6     0     0   \n",
       "\n",
       "      9     10       11    12    13    14              15  \n",
       "0  03 !  Total  № Games  01 !  02 !  03 !  Combined total  \n",
       "1     0      0       13     0     0     2               2  \n",
       "2     0      0       15     5     2     8              15  \n",
       "3     0      0       41    18    24    28              70  \n",
       "4     0      0       11     1     2     9              12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(inputFile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems pretty clear that the first row of data in the <b>`DataFrame`</b> is what we really want to see as the column names. It also seems like the first column in the data is the country name, which we would like to make an <b>index</b>.<br>\n",
    "Read csv has a number of parameters that we can use to indicate to Pandas how rows and columns should be labeled.<br>\n",
    "For instance, we can use the <b>`index_col`</b> to indicate which column should be the <b>index</b> and we can also use the header parameter to indicate which row from the data file should be used as the header. Let's re-import that data and center <b>index</b> value to be 0 which is the first column and let set a column headers to be read from the second row of data. We can do this by using the <b>`skiprows`</b> parameters, to tell Pandas to ignore the first row, which was made up of numeric column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>№ Summer</th>\n",
       "      <th>01 !</th>\n",
       "      <th>02 !</th>\n",
       "      <th>03 !</th>\n",
       "      <th>Total</th>\n",
       "      <th>№ Winter</th>\n",
       "      <th>01 !.1</th>\n",
       "      <th>02 !.1</th>\n",
       "      <th>03 !.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th>№ Games</th>\n",
       "      <th>01 !.2</th>\n",
       "      <th>02 !.2</th>\n",
       "      <th>03 !.2</th>\n",
       "      <th>Combined total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Australasia (ANZ) [ANZ]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         № Summer  01 !  02 !  03 !  Total  № Winter  01 !.1  \\\n",
       "Afghanistan (AFG)              13     0     0     2      2         0       0   \n",
       "Algeria (ALG)                  12     5     2     8     15         3       0   \n",
       "Argentina (ARG)                23    18    24    28     70        18       0   \n",
       "Armenia (ARM)                   5     1     2     9     12         6       0   \n",
       "Australasia (ANZ) [ANZ]         2     3     4     5     12         0       0   \n",
       "\n",
       "                         02 !.1  03 !.1  Total.1  № Games  01 !.2  02 !.2  \\\n",
       "Afghanistan (AFG)             0       0        0       13       0       0   \n",
       "Algeria (ALG)                 0       0        0       15       5       2   \n",
       "Argentina (ARG)               0       0        0       41      18      24   \n",
       "Armenia (ARM)                 0       0        0       11       1       2   \n",
       "Australasia (ANZ) [ANZ]       0       0        0        2       3       4   \n",
       "\n",
       "                         03 !.2  Combined total  \n",
       "Afghanistan (AFG)             2               2  \n",
       "Algeria (ALG)                 8              15  \n",
       "Argentina (ARG)              28              70  \n",
       "Armenia (ARM)                 9              12  \n",
       "Australasia (ANZ) [ANZ]       5              12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(inputFile, index_col = 0, skiprows = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data came from the all time Olympic games medal table on Wikipedia. If we head to the page we could see that instead of running gold, silver and bronze in the pages, these nice little icons with a one, a two, and a three in them In our csv file these were represented with the strings 01 !, 02 !, and so on. We see that the column values are repeated which really isn't good practice. Panda's recognize this in a panda.1 and .2 to make things more unique.<br>\n",
    "But this labeling isn't really as clear as it could be, so we should clean up the data file. We can of course do this just by going and editing the CSV file directly, but we can also set the column names using the Pandas <b>`name`</b>\n",
    "property.<br><br>\n",
    "Panda stores a list of all of the columns in the <b>`.`</b>columns attribute. We can change the values of the column names by iterating over this list and calling the <b>`rename`</b> method of the <b>`DataFrame`</b>. Now, I'm going to copy and paste this in to speed up things but we can walk through what is going on here.<br><br>\n",
    "Here we just iterate through all of the columns looking to see if they start with a 01, 02, 03 or numeric character. If they do, we can call <b>`rename`</b> and set the column parameters to a <b>dictionary</b> with the <b>keys</b> being the column we want to replace and the <b>value</b> being the new value we want.<br><br>\n",
    "Here we'll slice some of the old values in two, since we don't want to lose the unique appended values. We'll also set the ever-important <b>`inplace`</b> parameter to <b>true</b> so Pandas knows to update this <b>`dataframe`</b> directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Summer</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th># Winter</th>\n",
       "      <th>Gold.1</th>\n",
       "      <th>Silver.1</th>\n",
       "      <th>Bronze.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th># Games</th>\n",
       "      <th>Gold.2</th>\n",
       "      <th>Silver.2</th>\n",
       "      <th>Bronze.2</th>\n",
       "      <th>Combined total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Australasia (ANZ) [ANZ]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         # Summer  Gold  Silver  Bronze  Total  # Winter  \\\n",
       "Afghanistan (AFG)              13     0       0       2      2         0   \n",
       "Algeria (ALG)                  12     5       2       8     15         3   \n",
       "Argentina (ARG)                23    18      24      28     70        18   \n",
       "Armenia (ARM)                   5     1       2       9     12         6   \n",
       "Australasia (ANZ) [ANZ]         2     3       4       5     12         0   \n",
       "\n",
       "                         Gold.1  Silver.1  Bronze.1  Total.1  # Games  Gold.2  \\\n",
       "Afghanistan (AFG)             0         0         0        0       13       0   \n",
       "Algeria (ALG)                 0         0         0        0       15       5   \n",
       "Argentina (ARG)               0         0         0        0       41      18   \n",
       "Armenia (ARM)                 0         0         0        0       11       1   \n",
       "Australasia (ANZ) [ANZ]       0         0         0        0        2       3   \n",
       "\n",
       "                         Silver.2  Bronze.2  Combined total  \n",
       "Afghanistan (AFG)               0         2               2  \n",
       "Algeria (ALG)                   2         8              15  \n",
       "Argentina (ARG)                24        28              70  \n",
       "Armenia (ARM)                   2         9              12  \n",
       "Australasia (ANZ) [ANZ]         4         5              12  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if col[:2]=='01':\n",
    "        df.rename(columns={col:'Gold' + col[4:]}, inplace=True)\n",
    "    if col[:2]=='02':\n",
    "        df.rename(columns={col:'Silver' + col[4:]}, inplace=True)\n",
    "    if col[:2]=='03':\n",
    "        df.rename(columns={col:'Bronze' + col[4:]}, inplace=True)\n",
    "    if col[:1]=='№':\n",
    "        df.rename(columns={col:'#' + col[1:]}, inplace=True) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, that's more on the <b>`dataframe`</b> with a focus on the workflow of actually getting data in and into a place where we might want to query it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying a Data Frame\n",
    "Before we talk about how to query data frames, we need to talk about Boolean masking. Boolean masking is the heart of fast and efficient querying in NumPy. It's analogous a bit to masking used in other computational areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>Boolean mask</b> is an array which can be of one dimension like a series, or two dimensions like a data frame, where each of the values in the array are either true or false. This array is essentially overlaid on top of the data structure that we're querying. And any cell aligned with the true value will be admitted into our final result, and any sign aligned with a false value will not.<br><br>\n",
    "<b>Boolean mask</b>ing is powerful conceptually and is the cornerstone of efficient NumPy and pandas querying. This technique is well used in other areas of computer science, for instance, in graphics. But it doesn't really have an analogue in other traditional relational databases, so I think it's worth pointing out here. <b>Boolean mask</b>s are created by applying <b>operators</b> directly to the <b>`pandas`</b> series or <b>`DataFrame`</b> objects.<br><br> For instance, in our Olympics data set, you might be interested in seeing only those countries who have achieved a gold medal at the summer Olympics. To build a <b>Boolean mask</b> for this query, we project the gold column using the indexing operator and apply the greater than operator with a comparison value of zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gold'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4f4dc2921efb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gold'"
     ]
    }
   ],
   "source": [
    "df['Gold']>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially broadcasting a comparison operator, <b>`>`</b> greater than, with the results being returned as a Boolean series. The resultant series is indexed where the value of each cell is either true or false depending on whether a country has won at least one gold medal, and the index is the country name.<br><br>\n",
    "So this builds us the Boolean mask, which is half the battle. What we want to do next is overlay that mask on the data frame. We can do this using the where function. The where function takes a Boolean mask as a condition, applies it to the data frame or series, and returns a new data frame or series of the same shape. Let's apply this Boolean mask to our Olympics data and create a data frame of only those countries who have won a gold at a summer games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = df.where(df['Gold'] > 0)\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the resulting data frame keeps the original indexed values, and only data from countries that met the condition are retained. All of the countries which did not meet the condition have NaN data instead. This is okay. Most statistical functions built into the data frame object ignore values of NaN.<br><br>\n",
    "For instance, if we call the df.count on the only gold data frame, we see that there are 100 countries which have had gold medals awarded at the summer games, while if we call count on the original data frame, we see that there are 147 countries total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold['Gold'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gold'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to drop those rows which have no data. To do this, we can use the drop NA function. You can optionally provide drop NA the axes it should be considering. Remember that the axes is just an indicator for the columns or rows and that the default is zero, which means rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = only_gold.dropna()\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you find yourself talking about pandas and saying phrases like, often I want to, it's quite likely the developers have included a shortcut for this common operation. For instance, in this example, we don't actually have to use the where function explicitly. The pandas developers allow the indexing operator to take a Boolean mask as a value instead of just a list of column names. The syntax might look a little messy, especially if you're not used to programming languages with overloaded operators, but the result is that you're able to filter and reduce data frames relatively quickly.<br><br>\n",
    "Here's a more concise example of how we could query this data frame. You'll notice that there are no NaNs when you query the data frame in this manner. pandas automatically filters out the rows with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = df[df['Gold'] > 0]\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing to keep in mind if you're not used to Boolean or bit masking for data reduction. The output of two Boolean masks being compared with logical operators is another Boolean mask. This means that you can chain together a bunch of and/or statements in order to create more complex queries, and the result is a single Boolean mask.<br><br>\n",
    "For instance, we could create a mask for all of those countries who have received a gold in the summer Olympics and logically order that with all of those countries who have received a gold in the winter Olympics. If we apply this to the data frame and use the length function to see how many rows there are, we see that there are 101 countries which have won a gold metal at some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df['Gold'] > 0) | (df['Gold.1'] > 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example for fun. Have there been any countries who have only won a gold in the winter Olympics and never in the summer Olympics? Here's one way to answer that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Gold.1'] > 0) & (df['Gold'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor Liechtenstein. Thankfully the Olympics come every four years. I know who I'll be cheering for in 2020 to win their first summer gold.<br><br>\n",
    "Extremely important, and often an issue for new users, is to remember that each Boolean mask needs to be encased in parenthesis because of the order of operations. This can cause no end of frustration if you're not used to it, so be careful.<br><br>\n",
    "In this lecture, we took a look at Boolean masking. We didn't have much code to write, but applying masks to data frames is really a core panda's work flow and is worth practicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Dataframes\n",
    "As we've seen, both series and DataFrames can have indices applied to them. The index is essentially a row level label, and we know that rows correspond to axis zero. In our Olympics data, we indexed the data frame by the name of the country. Indices can either be inferred, such as when we create a new series without an index, in which case we get numeric values, or they can be set explicitly, like when we use the dictionary object to create the series, or when we loaded data from the CSV file and specified the header. Another option for setting an index is to use the set_index function. This function takes a list of columns and promotes those columns to an index. Set index is a destructive process, it doesn't keep the current index. If you want to keep the current index, you need to manually create a new column and copy into it values from the index attribute. Let's go back to our Olympics DataFrame. Let's say that we don't want to index the DataFrame by countries, but instead want to index by the number of gold medals that were won at summer games. First we need to preserve the country information into a new column. We can do this using the indexing operator or the string that has the column label. Then we can use the set_index to set index of the column to summer gold medal wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Summer</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th># Winter</th>\n",
       "      <th>Gold.1</th>\n",
       "      <th>Silver.1</th>\n",
       "      <th>Bronze.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th># Games</th>\n",
       "      <th>Gold.2</th>\n",
       "      <th>Silver.2</th>\n",
       "      <th>Bronze.2</th>\n",
       "      <th>Combined total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Algeria (ALG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Argentina (ARG)</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Armenia (ARM)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Australasia (ANZ) [ANZ]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         # Summer  Gold  Silver  Bronze  Total  # Winter  \\\n",
       "Afghanistan (AFG)              13     0       0       2      2         0   \n",
       "Algeria (ALG)                  12     5       2       8     15         3   \n",
       "Argentina (ARG)                23    18      24      28     70        18   \n",
       "Armenia (ARM)                   5     1       2       9     12         6   \n",
       "Australasia (ANZ) [ANZ]         2     3       4       5     12         0   \n",
       "\n",
       "                         Gold.1  Silver.1  Bronze.1  Total.1  # Games  Gold.2  \\\n",
       "Afghanistan (AFG)             0         0         0        0       13       0   \n",
       "Algeria (ALG)                 0         0         0        0       15       5   \n",
       "Argentina (ARG)               0         0         0        0       41      18   \n",
       "Armenia (ARM)                 0         0         0        0       11       1   \n",
       "Australasia (ANZ) [ANZ]       0         0         0        0        2       3   \n",
       "\n",
       "                         Silver.2  Bronze.2  Combined total  \n",
       "Afghanistan (AFG)               0         2               2  \n",
       "Algeria (ALG)                   2         8              15  \n",
       "Argentina (ARG)                24        28              70  \n",
       "Armenia (ARM)                   2         9              12  \n",
       "Australasia (ANZ) [ANZ]         4         5              12  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that when we create a new index from an existing column it appears that a new first row has been added with empty values. This isn't quite what's happening. And we know this in part because an empty value is actually rendered either as a none or an NaN if the data type of the column is numeric. What's actually happened is that the index has a name. Whatever the column name was in the Jupiter notebook has just provided this in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Summer</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th># Winter</th>\n",
       "      <th>Gold.1</th>\n",
       "      <th>Silver.1</th>\n",
       "      <th>Bronze.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th># Games</th>\n",
       "      <th>Gold.2</th>\n",
       "      <th>Silver.2</th>\n",
       "      <th>Bronze.2</th>\n",
       "      <th>Combined total</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan (AFG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>Algeria (ALG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>Argentina (ARG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>Armenia (ARM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>Australasia (ANZ) [ANZ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      # Summer  Silver  Bronze  Total  # Winter  Gold.1  Silver.1  Bronze.1  \\\n",
       "Gold                                                                          \n",
       "0           13       0       2      2         0       0         0         0   \n",
       "5           12       2       8     15         3       0         0         0   \n",
       "18          23      24      28     70        18       0         0         0   \n",
       "1            5       2       9     12         6       0         0         0   \n",
       "3            2       4       5     12         0       0         0         0   \n",
       "\n",
       "      Total.1  # Games  Gold.2  Silver.2  Bronze.2  Combined total  \\\n",
       "Gold                                                                 \n",
       "0           0       13       0         0         2               2   \n",
       "5           0       15       5         2         8              15   \n",
       "18          0       41      18        24        28              70   \n",
       "1           0       11       1         2         9              12   \n",
       "3           0        2       3         4         5              12   \n",
       "\n",
       "                      country  \n",
       "Gold                           \n",
       "0           Afghanistan (AFG)  \n",
       "5               Algeria (ALG)  \n",
       "18            Argentina (ARG)  \n",
       "1               Armenia (ARM)  \n",
       "3     Australasia (ANZ) [ANZ]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'] = df.index\n",
    "df = df.set_index('Gold')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get rid of the index completely by calling the function reset_index. This promotes the index into a column and creates a default numbered index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice feature of pandas is that it has the option to do multi-level indexing. This is similar to composite keys in relational database systems. To create a multi-level index, we simply call set index and give it a list of columns that we're interested in promoting to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "0      40       3         6      1       0  Alabama         Alabama   \n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "0        4779736            4780127          4785161  ...          0.002295   \n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "0         -0.193196          0.381066          0.582002         -0.467369   \n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "0     1.030015     0.826644     1.383282     1.724718     0.712594  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputFile = 'C:/Users/dfitzgerald/Documents/MyCourses/IntrotoDataScienceinPython/coursedownloads/census.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(inputFile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas will search through these in order, finding the distinct data and forming composite indices. A good example of this is often found when dealing with geographical data which is sorted by regions or demographics. Let's change data sets and look at some census data for a better example. This data is stored in the file census.csv and comes from the United States Census Bureau. In particular, this is a breakdown of the population level data at the US county level. It's a great example of how different kinds of data sets might be formatted when you're trying to clean them. For instance, in this data set there are two summarized levels, one that contains summary data for the whole country. And one that contains summary data for each state, and one that contains summary data for each county. I often find that I want to see a list of all the unique values in a given column. In this DataFrame, we see that the possible values for the sum level are using the unique function on the DataFrame. This is similar to the SQL distinct operator.<br><br>\n",
    "Here we can run <b>`unique`</b> on the sum level of our current <b>`DataFrame`</b>and see that there are only two different values, 40 and 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 50], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SUMLEV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of all of the rows that are summaries at the state level and just keep the county data. Also while this data set is interesting for a number of different reasons, let's reduce the data that we're going to look at to just the total population estimates and the total number of births. We can do this by creating a list of column names that we want to keep then project those and assign the resulting DataFrame to our df variable. The US Census data breaks down estimates of population data by state and county. We can load the data and set the index to be a combination of the state and county values and see how pandas handles it in a DataFrame. We do this by creating a list of the column identifiers we want to have indexed. And then calling set index with this list and assigning the output as appropriate. We see here that we have a dual index, first the state name and then the county name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>57322</td>\n",
       "      <td>57322</td>\n",
       "      <td>57373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807375</td>\n",
       "      <td>-1.177622</td>\n",
       "      <td>-1.748766</td>\n",
       "      <td>-2.062535</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>1.859511</td>\n",
       "      <td>-0.848580</td>\n",
       "      <td>-1.402476</td>\n",
       "      <td>-1.577232</td>\n",
       "      <td>-0.884411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "5      50       3         6      1       9  Alabama   Blount County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "5          57322              57322            57373  ...          1.807375   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "5         -1.177622         -1.748766         -2.062535         -1.369970   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "5     1.859511    -0.848580    -1.402476    -1.577232    -0.884411  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['SUMLEV'] == 50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>BIRTHS2010</th>\n",
       "      <th>BIRTHS2011</th>\n",
       "      <th>BIRTHS2012</th>\n",
       "      <th>BIRTHS2013</th>\n",
       "      <th>BIRTHS2014</th>\n",
       "      <th>BIRTHS2015</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>POPESTIMATE2011</th>\n",
       "      <th>POPESTIMATE2012</th>\n",
       "      <th>POPESTIMATE2013</th>\n",
       "      <th>POPESTIMATE2014</th>\n",
       "      <th>POPESTIMATE2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>151</td>\n",
       "      <td>636</td>\n",
       "      <td>615</td>\n",
       "      <td>574</td>\n",
       "      <td>623</td>\n",
       "      <td>600</td>\n",
       "      <td>54660</td>\n",
       "      <td>55253</td>\n",
       "      <td>55175</td>\n",
       "      <td>55038</td>\n",
       "      <td>55290</td>\n",
       "      <td>55347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>517</td>\n",
       "      <td>2187</td>\n",
       "      <td>2092</td>\n",
       "      <td>2160</td>\n",
       "      <td>2186</td>\n",
       "      <td>2240</td>\n",
       "      <td>183193</td>\n",
       "      <td>186659</td>\n",
       "      <td>190396</td>\n",
       "      <td>195126</td>\n",
       "      <td>199713</td>\n",
       "      <td>203709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>70</td>\n",
       "      <td>335</td>\n",
       "      <td>300</td>\n",
       "      <td>283</td>\n",
       "      <td>260</td>\n",
       "      <td>269</td>\n",
       "      <td>27341</td>\n",
       "      <td>27226</td>\n",
       "      <td>27159</td>\n",
       "      <td>26973</td>\n",
       "      <td>26815</td>\n",
       "      <td>26489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>44</td>\n",
       "      <td>266</td>\n",
       "      <td>245</td>\n",
       "      <td>259</td>\n",
       "      <td>247</td>\n",
       "      <td>253</td>\n",
       "      <td>22861</td>\n",
       "      <td>22733</td>\n",
       "      <td>22642</td>\n",
       "      <td>22512</td>\n",
       "      <td>22549</td>\n",
       "      <td>22583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>183</td>\n",
       "      <td>744</td>\n",
       "      <td>710</td>\n",
       "      <td>646</td>\n",
       "      <td>618</td>\n",
       "      <td>603</td>\n",
       "      <td>57373</td>\n",
       "      <td>57711</td>\n",
       "      <td>57776</td>\n",
       "      <td>57734</td>\n",
       "      <td>57658</td>\n",
       "      <td>57673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    STNAME         CTYNAME  BIRTHS2010  BIRTHS2011  BIRTHS2012  BIRTHS2013  \\\n",
       "1  Alabama  Autauga County         151         636         615         574   \n",
       "2  Alabama  Baldwin County         517        2187        2092        2160   \n",
       "3  Alabama  Barbour County          70         335         300         283   \n",
       "4  Alabama     Bibb County          44         266         245         259   \n",
       "5  Alabama   Blount County         183         744         710         646   \n",
       "\n",
       "   BIRTHS2014  BIRTHS2015  POPESTIMATE2010  POPESTIMATE2011  POPESTIMATE2012  \\\n",
       "1         623         600            54660            55253            55175   \n",
       "2        2186        2240           183193           186659           190396   \n",
       "3         260         269            27341            27226            27159   \n",
       "4         247         253            22861            22733            22642   \n",
       "5         618         603            57373            57711            57776   \n",
       "\n",
       "   POPESTIMATE2013  POPESTIMATE2014  POPESTIMATE2015  \n",
       "1            55038            55290            55347  \n",
       "2           195126           199713           203709  \n",
       "3            26973            26815            26489  \n",
       "4            22512            22549            22583  \n",
       "5            57734            57658            57673  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = ['STNAME',\n",
    "                   'CTYNAME',\n",
    "                   'BIRTHS2010',\n",
    "                   'BIRTHS2011',\n",
    "                   'BIRTHS2012',\n",
    "                   'BIRTHS2013',\n",
    "                   'BIRTHS2014',\n",
    "                   'BIRTHS2015',\n",
    "                   'POPESTIMATE2010',\n",
    "                   'POPESTIMATE2011',\n",
    "                   'POPESTIMATE2012',\n",
    "                   'POPESTIMATE2013',\n",
    "                   'POPESTIMATE2014',\n",
    "                   'POPESTIMATE2015']\n",
    "df = df[columns_to_keep]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An immediate question which comes up is how we can query this DataFrame. For instance, we saw previously that the loc attribute of the DataFrame can take multiple arguments. And it could query both the row and the columns. When you use a MultiIndex, you must provide the arguments in order by the level you wish to query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BIRTHS2010</th>\n",
       "      <th>BIRTHS2011</th>\n",
       "      <th>BIRTHS2012</th>\n",
       "      <th>BIRTHS2013</th>\n",
       "      <th>BIRTHS2014</th>\n",
       "      <th>BIRTHS2015</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>POPESTIMATE2011</th>\n",
       "      <th>POPESTIMATE2012</th>\n",
       "      <th>POPESTIMATE2013</th>\n",
       "      <th>POPESTIMATE2014</th>\n",
       "      <th>POPESTIMATE2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>151</td>\n",
       "      <td>636</td>\n",
       "      <td>615</td>\n",
       "      <td>574</td>\n",
       "      <td>623</td>\n",
       "      <td>600</td>\n",
       "      <td>54660</td>\n",
       "      <td>55253</td>\n",
       "      <td>55175</td>\n",
       "      <td>55038</td>\n",
       "      <td>55290</td>\n",
       "      <td>55347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>517</td>\n",
       "      <td>2187</td>\n",
       "      <td>2092</td>\n",
       "      <td>2160</td>\n",
       "      <td>2186</td>\n",
       "      <td>2240</td>\n",
       "      <td>183193</td>\n",
       "      <td>186659</td>\n",
       "      <td>190396</td>\n",
       "      <td>195126</td>\n",
       "      <td>199713</td>\n",
       "      <td>203709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Barbour County</td>\n",
       "      <td>70</td>\n",
       "      <td>335</td>\n",
       "      <td>300</td>\n",
       "      <td>283</td>\n",
       "      <td>260</td>\n",
       "      <td>269</td>\n",
       "      <td>27341</td>\n",
       "      <td>27226</td>\n",
       "      <td>27159</td>\n",
       "      <td>26973</td>\n",
       "      <td>26815</td>\n",
       "      <td>26489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bibb County</td>\n",
       "      <td>44</td>\n",
       "      <td>266</td>\n",
       "      <td>245</td>\n",
       "      <td>259</td>\n",
       "      <td>247</td>\n",
       "      <td>253</td>\n",
       "      <td>22861</td>\n",
       "      <td>22733</td>\n",
       "      <td>22642</td>\n",
       "      <td>22512</td>\n",
       "      <td>22549</td>\n",
       "      <td>22583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Blount County</td>\n",
       "      <td>183</td>\n",
       "      <td>744</td>\n",
       "      <td>710</td>\n",
       "      <td>646</td>\n",
       "      <td>618</td>\n",
       "      <td>603</td>\n",
       "      <td>57373</td>\n",
       "      <td>57711</td>\n",
       "      <td>57776</td>\n",
       "      <td>57734</td>\n",
       "      <td>57658</td>\n",
       "      <td>57673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        BIRTHS2010  BIRTHS2011  BIRTHS2012  BIRTHS2013  \\\n",
       "STNAME  CTYNAME                                                          \n",
       "Alabama Autauga County         151         636         615         574   \n",
       "        Baldwin County         517        2187        2092        2160   \n",
       "        Barbour County          70         335         300         283   \n",
       "        Bibb County             44         266         245         259   \n",
       "        Blount County          183         744         710         646   \n",
       "\n",
       "                        BIRTHS2014  BIRTHS2015  POPESTIMATE2010  \\\n",
       "STNAME  CTYNAME                                                   \n",
       "Alabama Autauga County         623         600            54660   \n",
       "        Baldwin County        2186        2240           183193   \n",
       "        Barbour County         260         269            27341   \n",
       "        Bibb County            247         253            22861   \n",
       "        Blount County          618         603            57373   \n",
       "\n",
       "                        POPESTIMATE2011  POPESTIMATE2012  POPESTIMATE2013  \\\n",
       "STNAME  CTYNAME                                                             \n",
       "Alabama Autauga County            55253            55175            55038   \n",
       "        Baldwin County           186659           190396           195126   \n",
       "        Barbour County            27226            27159            26973   \n",
       "        Bibb County               22733            22642            22512   \n",
       "        Blount County             57711            57776            57734   \n",
       "\n",
       "                        POPESTIMATE2014  POPESTIMATE2015  \n",
       "STNAME  CTYNAME                                           \n",
       "Alabama Autauga County            55290            55347  \n",
       "        Baldwin County           199713           203709  \n",
       "        Barbour County            26815            26489  \n",
       "        Bibb County               22549            22583  \n",
       "        Blount County             57658            57673  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index(['STNAME', 'CTYNAME'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside of the index, each column is called a level and the outermost column is level zero. For instance, if we want to see the population results from Washtenaw County, which is where I live, you'd want to the first argument as the state of Michigan. You might be interested in just comparing two counties. For instance, Washtenaw where I live and Wayne County which covers Detroit. To do this, we can pass the loc method, a list of tuples which describe the indices we wish to query. Since we have a MultiIndex of two values, the state and the county, we need to provide two values as each element of our filtering list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIRTHS2010            977\n",
       "BIRTHS2011           3826\n",
       "BIRTHS2012           3780\n",
       "BIRTHS2013           3662\n",
       "BIRTHS2014           3683\n",
       "BIRTHS2015           3709\n",
       "POPESTIMATE2010    345563\n",
       "POPESTIMATE2011    349048\n",
       "POPESTIMATE2012    351213\n",
       "POPESTIMATE2013    354289\n",
       "POPESTIMATE2014    357029\n",
       "POPESTIMATE2015    358880\n",
       "Name: (Michigan, Washtenaw County), dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Michigan', 'Washtenaw County']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "level name STNAME is not the name of the index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-52e0e5c25c53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'STNAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   7892\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7893\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7894\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7895\u001b[0m         )\n\u001b[0;32m   7896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2520\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             )\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    499\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m                     raise ValueError(\n\u001b[1;32m--> 501\u001b[1;33m                         \u001b[1;34m\"level name {} is not the name of the \"\u001b[0m \u001b[1;34m\"index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m                     )\n\u001b[0;32m    503\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: level name STNAME is not the name of the index"
     ]
    }
   ],
   "source": [
    "df.groupby(level='STNAME').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ [('Michigan', 'Washtenaw County'),\n",
    "         ('Michigan', 'Wayne County')] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so that's how hierarchical indices work in a nutshell. They're a special part of the pandas library which I think can make management and reasoning about data easier. Of course hierarchical labeling isn't just for rows. For example, you can transpose this matrix and now have hierarchical column labels. And projecting a single column which has these labels works exactly the way you would expect it to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "We're going to end this week of lecture with a quick discussion of missing values. We've seen a preview of how Pandas handles missing values using the None type and NumPy NaN values. Missing values are pretty common in data cleaning activities. There are couple of caveats and discussion points which we should address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = 'C:/Users/dfitzgerald/Documents/MyCourses/IntrotoDataScienceinPython/coursedownloads/log.csv'\n",
    "\n",
    "df = pd.read_csv(inputFile)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the built in loading from delimited files provides control for missing values in a few ways. The most germane of these, is the na_values list, to indicate other strings which could refer to missing values. Some of my sociologist colleagues for instance, regularly use the value of 99 in binary categories to indicate that there's no value. So this comes in handy. You can also use the na_filter option to turn off white space filtering, if white space is an actual value of interest. But in practice, this is pretty rare. In addition to rules controlling how missing values might be loaded, it's sometimes useful to consider missing values as actually having information. I'll give an example from my own research. I often deal with logs from online learning systems. In particular, I've done a couple of projects looking at video use in lecture capture systems. In these systems it's common for the player for have a heartbeat functionality where playback statistics are sent to the server every so often, maybe every 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These heartbeats can get big as they can carry the whole state of the playback system, such as where the video play head is at, where the video size is, which video is being rendered to the screen, how loud the volume is, etc.<br><br>\n",
    "If we load the data file log.txt, we can see an example of what this might look like. In this data the first column is a timestamp in the Unix epoch format. The next column is the user name followed by a web page they're visiting and the video that they're playing.<br><br>\n",
    "Each row of the DataFrame has a playback position. And we can see that as the playback position increases by one, the time stamp increases by about 30 seconds.\n",
    "Except for user Bob. It turns out that Bob has paused his playback so as time increases the playback position doesn't change. Note too how difficult it is for us to try and derive this knowledge from the data, because it's not sorted by time stamp as one might expect. This is actually not uncommon on systems which have a high degree of parallelism.\n",
    "There are a lot of missing values in the paused and volume columns. It's not efficient to send this information across the network if it hasn't changed. So this particular system just inserts null values into the database if there's no changes.\n",
    "One of the handy functions that Pandas has for working with missing values is the filling function, fillna. This function takes a number or parameters, for instance, you could pass in a single value which is called a scalar value to change all of the missing data to one value. This isn't really applicable in this case, but it's a pretty common use case. Next up though is the method parameter. The two common fill values are ffill and bfill. ffill is for forward filling and it updates an na value for a particular cell with the value from the previous row. It's important to note that your data needs to be sorted in order for this to have the effect you might want. Data that comes from traditional database management systems usually has no order guarantee, just like this data. So be careful.\n",
    "Start transcript at \n",
    "In Pandas we can sort either by index or by values. Here we'll just promote the time stamp to an index then sort on the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('time')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look closely at the output though we'll notice that the index isn't really unique. Two users seem to be able to use the system at the same time. Again, a very common case.\n",
    "\n",
    "Let's reset the index, and use some multi-level indexing instead, and promote the user name to a second level of the index to deal with that issue.\n",
    "\n",
    "Now that we have the data indexed and sorted appropriately, we can fill the missing datas using ffill. It's good to remember when dealing with missing values so you can deal with individual columns or sets of columns by projecting them just as we spoke about earlier. So you don't have to fix all missing values in one command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.set_index(['time', 'user'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's sometimes useful to use forward filling, sometimes backwards filling, and sometimes useful to just use a single number. More recently, the Pandas team introduced a method of filling missing values with a series which is the same length as your DataFrame. This makes it easy to derive values which are missing if you have the underlying to do so. For instance, if you're dealing with receipts and you have a column for final price and a column for discount but are missing information from the original price column, you can fill this automatically using fillna.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last note on missing values. When you use statistical functions on DataFrames, these functions typically ignore missing values. For instance if you try and calculate the mean value of a DataFrame, the underlying NumPy function will ignore missing values. This is usually what you want but you should be aware that values are being excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "All questions are weighted the same in this assignment.\n",
    "## Part 1\n",
    "The following code loads the olympics dataset (olympics.csv), which was derrived from the Wikipedia entry on [All Time Olympic Games Medals](https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table), and does some basic data cleaning. \n",
    "\n",
    "The columns are organized as # of Summer games, Summer medals, # of Winter games, Winter medals, total # number of games, total # of medals. Use this dataset to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Summer</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th># Winter</th>\n",
       "      <th>Gold.1</th>\n",
       "      <th>Silver.1</th>\n",
       "      <th>Bronze.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th># Games</th>\n",
       "      <th>Gold.2</th>\n",
       "      <th>Silver.2</th>\n",
       "      <th>Bronze.2</th>\n",
       "      <th>Combined total</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Algeria</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>ALG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Argentina</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Armenia</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>ARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Australasia</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>ANZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             # Summer  Gold  Silver  Bronze  Total  # Winter  Gold.1  \\\n",
       "Afghanistan        13     0       0       2      2         0       0   \n",
       "Algeria            12     5       2       8     15         3       0   \n",
       "Argentina          23    18      24      28     70        18       0   \n",
       "Armenia             5     1       2       9     12         6       0   \n",
       "Australasia         2     3       4       5     12         0       0   \n",
       "\n",
       "             Silver.1  Bronze.1  Total.1  # Games  Gold.2  Silver.2  Bronze.2  \\\n",
       "Afghanistan         0         0        0       13       0         0         2   \n",
       "Algeria             0         0        0       15       5         2         8   \n",
       "Argentina           0         0        0       41      18        24        28   \n",
       "Armenia             0         0        0       11       1         2         9   \n",
       "Australasia         0         0        0        2       3         4         5   \n",
       "\n",
       "             Combined total   ID  \n",
       "Afghanistan               2  AFG  \n",
       "Algeria                  15  ALG  \n",
       "Argentina                70  ARG  \n",
       "Armenia                  12  ARM  \n",
       "Australasia              12  ANZ  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inputFile = 'C:/Users/dfitzgerald/Documents/MyCourses/IntrotoDataScienceinPython/coursedownloads/olympics.csv'\n",
    "\n",
    "df = pd.read_csv(inputFile, index_col=0, skiprows=1)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col[:2]=='01':\n",
    "        df.rename(columns={col:'Gold'+col[4:]}, inplace=True)\n",
    "    if col[:2]=='02':\n",
    "        df.rename(columns={col:'Silver'+col[4:]}, inplace=True)\n",
    "    if col[:2]=='03':\n",
    "        df.rename(columns={col:'Bronze'+col[4:]}, inplace=True)\n",
    "    if col[:1]=='№':\n",
    "        df.rename(columns={col:'#'+col[1:]}, inplace=True)\n",
    "\n",
    "names_ids = df.index.str.split('\\s\\(') # split the index by '('\n",
    "\n",
    "df.index = names_ids.str[0] # the [0] element is the country name (new index) \n",
    "df['ID'] = names_ids.str[1].str[:3] # the [1] element is the abbreviation or ID (take first 3 characters from that)\n",
    "\n",
    "df = df.drop('Totals')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Which country has won the most gold medals in summer games?\n",
    "\n",
    "This function should return a single string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "976",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 976",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-b6325add615c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 976"
     ]
    }
   ],
   "source": [
    "df[df['Gold'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Which country had the biggest difference between their summer and winter gold medal counts?\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Gold'] - df['Gold.1']).abs().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Which country has the biggest difference between their summer gold medal counts and winter gold medal counts relative to their total gold medal count? \n",
    "\n",
    "$$\\frac{Summer~Gold - Winter~Gold}{Total~Gold}$$\n",
    "\n",
    "Only include countries that have won at least 1 gold in both summer and winter.\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bulgaria'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria = df[(df['Gold.1'] > 0) & (df['Gold'] > 0)]\n",
    "country = ((criteria['Gold'] - criteria['Gold.1'])/criteria['Gold.2']).abs().idxmax()\n",
    "country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Write a function that creates a Series called \"Points\" which is a weighted value where each gold medal (`Gold.2`) counts for 3 points, silver medals (`Silver.2`) for 2 points, and bronze medals (`Bronze.2`) for 1 point. The function should return only the column (a Series object) which you created, with the country names as indices.\n",
    "\n",
    "*This function should return a Series named `Points` of length 146*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Afghanistan                           2\n",
       "Algeria                              27\n",
       "Argentina                           130\n",
       "Armenia                              16\n",
       "Australasia                          22\n",
       "                                   ... \n",
       "Yugoslavia                          171\n",
       "Independent Olympic Participants      4\n",
       "Zambia                                3\n",
       "Zimbabwe                             18\n",
       "Mixed team                           38\n",
       "Name: Points, Length: 146, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = (df['Gold.2']*3)+(df['Silver.2']*2)+(df['Bronze.2'])\n",
    "res.name = 'Points'\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "For the next set of questions, we will be using census data from the [United States Census Bureau](http://www.census.gov). Counties are political and geographic subdivisions of states in the United States. This dataset contains population data for counties and states in the US from 2010 to 2015. [See this document](https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2015/co-est2015-alldata.pdf) for a description of the variable names.\n",
    "\n",
    "The census dataset (census.csv) should be loaded as census_df. Answer questions using this as appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "0      40       3         6      1       0  Alabama         Alabama   \n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "0        4779736            4780127          4785161  ...          0.002295   \n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "0         -0.193196          0.381066          0.582002         -0.467369   \n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "0     1.030015     0.826644     1.383282     1.724718     0.712594  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputFile = 'C:/Users/dfitzgerald/Documents/MyCourses/IntrotoDataScienceinPython/coursedownloads/census.csv'\n",
    "census_df = pd.read_csv(inputFile)\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Which state has the most counties in it? (hint: consider the sumlevel key carefully! You'll need this for future questions too...)\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    mydf=census_df[census_df['SUMLEV'] == 50]\n",
    "    mydf = mydf.groupby('STNAME').count()['SUMLEV']\n",
    "    return mydf[mydf==mydf.max()].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Texas'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = census_df[census_df['SUMLEV'] == 50]\n",
    "res = res.groupby('STNAME').count()['SUMLEV']\n",
    "res[res==res.max()].index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Only looking at the three most populous counties for each state**, what are the three most populous states (in order of highest population to lowest population)? Use `CENSUS2010POP`.\n",
    "\n",
    "*This function should return a list of string values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['California', 'Texas', 'Illinois']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf=census_df[['SUMLEV','STNAME','CENSUS2010POP']]\n",
    "mydf=mydf[mydf['SUMLEV']==50]\n",
    "mydf=mydf.sort_values(by=['STNAME','CENSUS2010POP'], ascending=[True,False])\n",
    "mydf=mydf.groupby('STNAME').head(3)\n",
    "mydf=mydf.groupby('STNAME').sum()\n",
    "mydf=mydf.nlargest(3,'CENSUS2010POP')\n",
    "list(mydf.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Which county has had the largest absolute change in population within the period 2010-2015? (Hint: population values are stored in columns POPESTIMATE2010 through POPESTIMATE2015, you need to consider all six columns.)\n",
    "\n",
    "e.g. If County Population in the 5 year period is 100, 120, 80, 105, 100, 130, then its largest change in the period would be |130-80| = 50.\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harris County'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mydf=census_df[census_df['SUMLEV']==50]\n",
    "mydf=mydf[['CTYNAME','POPESTIMATE2010', 'POPESTIMATE2011','POPESTIMATE2012','POPESTIMATE2013','POPESTIMATE2014','POPESTIMATE2015']]\n",
    "mydf\n",
    "max_pop=map(max,mydf['POPESTIMATE2010'],mydf['POPESTIMATE2011'],mydf['POPESTIMATE2012'],mydf['POPESTIMATE2013'],mydf['POPESTIMATE2014'],mydf['POPESTIMATE2015'])\n",
    "max_pop=np.array(list(max_pop))\n",
    "min_pop=map(min,mydf['POPESTIMATE2010'],mydf['POPESTIMATE2011'],mydf['POPESTIMATE2012'],mydf['POPESTIMATE2013'],mydf['POPESTIMATE2014'],mydf['POPESTIMATE2015'])\n",
    "min_pop=np.array(list(min_pop))\n",
    "chg=max_pop-min_pop\n",
    "mydf.iloc[chg.argmax()].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "In this datafile, the United States is broken up into four regions using the \"REGION\" column. \n",
    "\n",
    "Create a query that finds the counties that belong to regions 1 or 2, whose name starts with 'Washington', and whose POPESTIMATE2015 was greater than their POPESTIMATE 2014.\n",
    "\n",
    "*This function should return a 5x2 DataFrame with the columns = ['STNAME', 'CTYNAME'] and the same index ID as the census_df (sorted ascending by index).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1419</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2355</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3163</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STNAME            CTYNAME\n",
       "896           Iowa  Washington County\n",
       "1419     Minnesota  Washington County\n",
       "2345  Pennsylvania  Washington County\n",
       "2355  Rhode Island  Washington County\n",
       "3163     Wisconsin  Washington County"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = census_df[(census_df['SUMLEV']==50) & (census_df['REGION']<=2) & (census_df['CTYNAME'].str.match('^Washington')) & (census_df['POPESTIMATE2015'] > census_df['POPESTIMATE2014'])]\n",
    "mydf[['STNAME','CTYNAME']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
